{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea8f1a83-29cd-40da-b791-16225a012bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ray head...\n",
      "Could not start ray head.\n",
      "Could not start some of the ray workloads. Ensure ray is able to run in your environment and you have the resources in your CML workspace to provision the specified amount of ray workloads.\n",
      "Set a longer timeout period if your CML workspace needs time to scale.\n",
      "Shutting down Ray cluster..\n"
     ]
    }
   ],
   "source": [
    "from cmlextensions.ray_cluster import RayCluster\n",
    "\n",
    "cluster = RayCluster(num_workers=2, worker_cpu=1, worker_memory=2, head_cpu=1, head_memory=1,worker_nvidia_gpu=1, dashboard_port=8080)\n",
    "cluster.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d410c7-2388-42ad-ab33-2bec309682dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "649f2e11-aace-4b2d-a966-295bd0b2aa25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage stats collection is disabled.\n",
      "\n",
      "Local node IP: 100.100.99.7\n",
      "2024-08-22 10:13:52,131\tWARNING services.py:2017 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=1.82gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "\n",
      "--------------------\n",
      "Ray runtime started.\n",
      "--------------------\n",
      "\n",
      "Next steps\n",
      "  To add another node to this Ray cluster, run\n",
      "    ray start --address='100.100.99.7:6379'\n",
      "  \n",
      "  To connect to this Ray cluster:\n",
      "    import ray\n",
      "    ray.init()\n",
      "  \n",
      "  To terminate the Ray runtime, run\n",
      "    ray stop\n",
      "  \n",
      "  To view the status of the cluster, use\n",
      "    ray status\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!ray start --head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34da439a-36ed-4402-b77d-bf0cd34648da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: ray dashboard [OPTIONS] CLUSTER_CONFIG_FILE\n",
      "Try 'ray dashboard --help' for help.\n",
      "\n",
      "Error: Missing argument 'CLUSTER_CONFIG_FILE'.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!ray dashboard -p $CDSW_READONLY_PORT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f07190f2-3b93-484c-9fb2-1422144ea70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/cloudera/cmlextensions.git\n",
      "  Cloning https://github.com/cloudera/cmlextensions.git to /tmp/pip-req-build-28n__tyn\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/cloudera/cmlextensions.git /tmp/pip-req-build-28n__tyn\n",
      "  Resolved https://github.com/cloudera/cmlextensions.git to commit d30304e29ab636d238b612119c54648825fb149d\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: cmlextensions\n",
      "  Building wheel for cmlextensions (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cmlextensions: filename=cmlextensions-0.1-py3-none-any.whl size=13977 sha256=7006a0ae9d082cdf430dea2b845fb98d9dc17a908a21e148b79838896740d035\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-cpg5l01f/wheels/7f/6d/42/9bc19a827652fdc63a1e3379c87895185da77124f921b4fbdb\n",
      "Successfully built cmlextensions\n",
      "Installing collected packages: cmlextensions\n",
      "Successfully installed cmlextensions-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/cloudera/cmlextensions.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b6fb869-41ec-42a9-9aa7-272580109713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmlextensions.ray_cluster import RayCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de61df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import ray\n",
    "import modin.pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a2b4b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Ray with GPU resources\n",
    "ray.init()\n",
    "\n",
    "@ray.remote(num_gpus=0.5)\n",
    "def process_large_dataset(task_id, num_rows):\n",
    "    print(f\"Task {task_id} using 0.5 GPU started.\")\n",
    "    \n",
    "    # Create a large DataFrame using Modin\n",
    "    df = pd.DataFrame(np.random.rand(num_rows, 10), columns=[f'col_{i}' for i in range(10)])\n",
    "    \n",
    "    # Perform some operations on the DataFrame\n",
    "    result = df.apply(lambda x: x ** 2).sum()\n",
    "    \n",
    "    print(f\"Task {task_id} using 0.5 GPU completed.\")\n",
    "    return f\"Result of task {task_id} is:\\n{result}\"\n",
    "\n",
    "@ray.remote(num_gpus=0.25)\n",
    "def filter_large_dataset(task_id, num_rows):\n",
    "    print(f\"Task {task_id} using 0.25 GPU started.\")\n",
    "    \n",
    "    # Create a large DataFrame using Modin\n",
    "    df = pd.DataFrame(np.random.rand(num_rows, 10), columns=[f'col_{i}' for i in range(10)])\n",
    "    \n",
    "    # Filter the DataFrame\n",
    "    filtered_df = df[df['col_0'] > 0.5]\n",
    "    \n",
    "    print(f\"Task {task_id} using 0.25 GPU completed.\")\n",
    "    return f\"Filtered DataFrame for task {task_id} has {len(filtered_df)} rows\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a302425-f604-4a8b-bef2-e8aa18561d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(process_large_dataset pid=7306)\u001b[0m Task 1 using 0.5 GPU started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(process_large_dataset pid=7306)\u001b[0m UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(filter_large_dataset pid=7308)\u001b[0m Task 2 using 0.25 GPU completed.\n",
      "\u001b[36m(filter_large_dataset pid=7308)\u001b[0m Task 2 using 0.25 GPU started.\n",
      "\u001b[36m(process_large_dataset pid=8532)\u001b[0m Task 3 using 0.5 GPU started.\n",
      "\u001b[36m(process_large_dataset pid=7306)\u001b[0m Task 1 using 0.5 GPU completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(process_large_dataset pid=8532)\u001b[0m UserWarning: Distributing <class 'numpy.ndarray'> object. This may take some time.\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of task 1 is:\n",
      "col_0    333505.092446\n",
      "col_1    333221.526196\n",
      "col_2    333303.259179\n",
      "col_3    333653.284097\n",
      "col_4    333705.498627\n",
      "col_5    333112.887854\n",
      "col_6    332928.717787\n",
      "col_7    332668.340261\n",
      "col_8    333627.419843\n",
      "col_9    333288.985124\n",
      "dtype: float64\n",
      "Filtered DataFrame for task 2 has 499360 rows\n",
      "Result of task 3 is:\n",
      "col_0    333202.479034\n",
      "col_1    333062.903244\n",
      "col_2    333455.487117\n",
      "col_3    333298.166438\n",
      "col_4    333654.189940\n",
      "col_5    333604.595087\n",
      "col_6    333584.404244\n",
      "col_7    333362.632928\n",
      "col_8    333527.654247\n",
      "col_9    333377.207994\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    num_rows = 10**6  # Example size of the dataset\n",
    "\n",
    "    # Launch tasks with GPU slicing\n",
    "    task1 = process_large_dataset.remote(1, num_rows)\n",
    "    task2 = filter_large_dataset.remote(2, num_rows)\n",
    "    task3 = process_large_dataset.remote(3, num_rows)\n",
    "\n",
    "    # Gather results\n",
    "    results = ray.get([task1, task2, task3])\n",
    "\n",
    "    # Print results\n",
    "    for result in results:\n",
    "        print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    ray.shutdown()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb866ad3-7eb9-4372-9b4b-8ec255e2fd6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
